---
- name: Deploy DeepSeek R1 Model
  shell: |
    kollama deploy {{ item }} -n {{ _deepseek.namespace }} --expose --service-type=LoadBalancer
  register: deploy_dsr1_model
  args:
    executable: /bin/bash
    chdir: "{{ base_path }}"
  environment:
    PATH: "/root/go/bin:{{ ansible_env.PATH }}"
  with_items:
    - deepseek-r1
    # - phi
    # - phi4
- debug: msg={{ deploy_dsr1_model }}
  when: print_debug == true


# To start a chat with ollama:
#
# OLLAMA_HOST=192.168.1.171:32379 ollama run deepseek-r1
#
# To integrate with your OpenAI API compatible client:
#
#  curl http://192.168.1.171:32379/v1/chat/completions -H "Content-Type: application/json" -d '{
#    "model": "phi",
#    "messages": [
#      {
#        "role": "user",
#        "content": "Hello!"
#      }
#    ]
# }'


# kubectl wait --for=jsonpath='{.status.readyReplicas}'=1 deployment/ollama-model-phi -n ollama-operator-system

# OLLAMA_HOST=192.168.1.171:32379 ollama run deepseek-r1 # phi, phi4


